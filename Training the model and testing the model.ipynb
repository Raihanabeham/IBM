{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Image Preprocessing"
      ],
      "metadata": {
        "id": "CCva2FnsFc5l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aZBTM-X7o5BH",
        "outputId": "f4e353ea-a1bf-4c28-d9c2-e8a02737ea75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/project/conversation engine for deaf and dumb.zip\n",
            "replace Dataset/test_set/A/1.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "!unzip '/content/drive/MyDrive/project/conversation engine for deaf and dumb.zip'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "wFNTEHYpq5hP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255,zoom_range=0.2,horizontal_flip=True,vertical_flip=False)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255)"
      ],
      "metadata": {
        "id": "5J5NFfYJrV0n"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd/content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "f7nJpAjcD5Vx",
        "outputId": "ae243f57-3978-425b-8995-918ffe8bbb24"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_datagen.flow_from_directory('/content/drive/MyDrive/Dataset/training_set',target_size=(64,64), batch_size=300,class_mode='categorical', color_mode = \"grayscale\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QLVgRLhksEwn",
        "outputId": "f5d1dca0-37f5-442e-9fb4-74f788da47a8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15750 images belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = test_datagen.flow_from_directory('/content/drive/MyDrive/Dataset/test_set',target_size=(64,64), batch_size=300,class_mode='categorical', color_mode = \"grayscale\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hGkYVCc_FA53",
        "outputId": "a79dba23-ffa7-43fb-e0ad-2ce4839220a0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2250 images belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ARRT6DZIFZmI",
        "outputId": "65aeb130-98d0-48d3-ac91-9bba962485c9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building"
      ],
      "metadata": {
        "id": "UCSSO1Itm4z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten"
      ],
      "metadata": {
        "id": "4lz1QRMxnGE8"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()"
      ],
      "metadata": {
        "id": "-qNpZQnto8b4"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Convolution2D(32, (3,3), input_shape=(64,64,1), activation='relu'))"
      ],
      "metadata": {
        "id": "zWhlLuZwpKNe"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "metadata": {
        "id": "csEwQMJzqG6_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "626wceskqfMu"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WtEU3Bamta-M",
        "outputId": "ade2b59c-b293-4f30-bc4b-e413a68c69d1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 62, 62, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 31, 31, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 30752)             0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320\n",
            "Trainable params: 320\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense (units=512, activation='relu'))"
      ],
      "metadata": {
        "id": "j7hl4_3DqoI8"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense (units=9, activation='softmax'))"
      ],
      "metadata": {
        "id": "XHbA5ev0qprq"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SOOjRh3fquHL"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2jqpqXimt5v2",
        "outputId": "6a7bdfb5-f53e-457e-f4ac-bbec52dabd8f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(x_train, steps_per_epoch=24, epochs=10, validation_data=x_test, validation_steps=40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dtqg5Ak-rBSn",
        "outputId": "088bbe4c-8899-4b5c-a8fa-87d56d9d0a4b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9974"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r24/24 [==============================] - 52s 2s/step - loss: 0.0123 - accuracy: 0.9974 - val_loss: 0.2475 - val_accuracy: 0.9756\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 40s 2s/step - loss: 0.0108 - accuracy: 0.9982\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 40s 2s/step - loss: 0.0096 - accuracy: 0.9982\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 39s 2s/step - loss: 0.0105 - accuracy: 0.9974\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 39s 2s/step - loss: 0.0110 - accuracy: 0.9974\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 40s 2s/step - loss: 0.0062 - accuracy: 0.9990\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 39s 2s/step - loss: 0.0066 - accuracy: 0.9990\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 40s 2s/step - loss: 0.0038 - accuracy: 0.9996\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 39s 2s/step - loss: 0.0040 - accuracy: 0.9993\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 39s 2s/step - loss: 0.0038 - accuracy: 0.9996\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4762fd0b50>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('conversation deaf and dumb.h5')"
      ],
      "metadata": {
        "id": "MDUiszqx8H2V"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test the model"
      ],
      "metadata": {
        "id": "5vLrS_cX8pw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model \n",
        "import numpy as np\n",
        "import cv2"
      ],
      "metadata": {
        "id": "kaIABXqu8oHN"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=load_model('conversation deaf and dumb.h5')"
      ],
      "metadata": {
        "id": "qvglSBXV9Mop"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize\n",
        "def detect(frame):\n",
        "      img = resize(frame, (64,64,1))\n",
        "      img = np.expand_dims(img,axis=0) \n",
        "      if(np.max(img)>1):\n",
        "        img=img/255.0\n",
        "      prediction = model.predict(img)\n",
        "      print(prediction)\n",
        "      prediction = model.predict_classes(img)\n",
        "      print(prediction)"
      ],
      "metadata": {
        "id": "9groGeew9lk9"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame=cv2.imread(r\"/content/drive/MyDrive/Dataset/test_set/D/10.png\")\n",
        "data = detect(frame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "RGYhodA8_0qk",
        "outputId": "78ce5016-db06-4b8f-d93d-304c41139b8d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "[[3.0667040e-09 3.7450640e-08 5.0424187e-12 9.9998152e-01 2.2859432e-08\n",
            "  2.1197555e-09 1.1723517e-09 4.2331633e-12 1.8421955e-05]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-0ec5e61a7a5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"/content/drive/MyDrive/Dataset/test_set/D/10.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-1e7cbb5c86f6>\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
          ]
        }
      ]
    }
  ]
}